import pdb
import logging
import shutil
import json
import threading
import queue
import time
import os
import glob
import asyncio
import argparse
import sys
import socket
import re

from dotenv import load_dotenv

# Create a class to collect and manage extracted data
class ExtractedDataCollector:
    def __init__(self):
        self.data = []
        self.data_by_type = {}  # Organize data by type
        self.data_by_source = {}  # Organize data by source
        self.data_by_timestamp = {}  # Organize data by timestamp (hour)
        self.lock = threading.Lock()
        self.metadata = {
            "total_items": 0,
            "types": set(),
            "sources": set(),
            "first_timestamp": None,
            "last_timestamp": None,
            "webpage_count": 0  # Track number of webpages captured
        }
    
    def add_data(self, json_data):
        """Add extracted data to the collection with metadata."""
        try:
            # Parse the JSON if it's a string
            if isinstance(json_data, str):
                data_obj = json.loads(json_data)
            else:
                data_obj = json_data
            
            # Add timestamp if not present
            if "timestamp" not in data_obj:
                data_obj["timestamp"] = time.time()
            
            # Add source if not present
            if "source" not in data_obj:
                data_obj["source"] = "unknown"
                
            # Add type if not present
            if "type" not in data_obj:
                # Try to infer type from content
                if "message" in data_obj:
                    data_obj["type"] = "log"
                elif "html" in data_obj:
                    data_obj["type"] = "html"
                    # Track webpage count for HTML content
                    self.metadata["webpage_count"] += 1
                elif "text" in data_obj:
                    data_obj["type"] = "text"
                elif "url" in data_obj:
                    # Ensure URL-related content is properly typed
                    data_obj["type"] = "webpage"
                    # Track webpage count
                    self.metadata["webpage_count"] += 1
                else:
                    data_obj["type"] = "unknown"
            
            # Ensure full content preservation for webpages
            if "html_content" in data_obj or "page_content" in data_obj or "url" in data_obj:
                # Mark as webpage data to ensure it's preserved in exports
                if "type" not in data_obj or data_obj["type"] not in ["html", "webpage"]:
                    data_obj["type"] = "webpage"
                    # Track webpage count
                    self.metadata["webpage_count"] += 1
            
            with self.lock:
                # Add to main data list
                self.data.append(data_obj)
                
                # Organize by type
                data_type = data_obj.get("type", "unknown")
                if not isinstance(data_type, str):
                    data_type = str(data_type)
                
                if data_type not in self.data_by_type:
                    self.data_by_type[data_type] = []
                self.data_by_type[data_type].append(data_obj)
                
                # Organize by source
                source = data_obj.get("source", "unknown")
                if not isinstance(source, str):
                    source = str(source)
                
                if source not in self.data_by_source:
                    self.data_by_source[source] = []
                self.data_by_source[source].append(data_obj)
                
                # Organize by timestamp (hour)
                timestamp = data_obj.get("timestamp", time.time())
                hour = time.strftime("%Y-%m-%d %H", time.localtime(timestamp))
                if hour not in self.data_by_timestamp:
                    self.data_by_timestamp[hour] = []
                self.data_by_timestamp[hour].append(data_obj)
                
                # Update metadata
                self.metadata["total_items"] += 1
                self.metadata["types"].add(data_type)
                self.metadata["sources"].add(source)
                
                if self.metadata["first_timestamp"] is None or timestamp < self.metadata["first_timestamp"]:
                    self.metadata["first_timestamp"] = timestamp
                
                if self.metadata["last_timestamp"] is None or timestamp > self.metadata["last_timestamp"]:
                    self.metadata["last_timestamp"] = timestamp
            
            return True
        except Exception as e:
            logging.error(f"Error adding data to collector: {str(e)}")
            return False
    
    def get_data(self):
        """Get all collected data as a list."""
        with self.lock:
            return self.data.copy()
    
    def get_data_json(self):
        """Get all collected data as a JSON string."""
        with self.lock:
            return json.dumps(self.data, indent=2)
    
    def get_data_by_type(self, data_type):
        """
        Get data filtered by type.
        
        Args:
            data_type: Type of data to filter (str or list)
            
        Returns:
            List of data items matching the type
        """
        with self.lock:
            # Handle potential list input from Gradio
            if isinstance(data_type, list):
                if len(data_type) > 0:
                    data_type = data_type[0]
                else:
                    return self.data.copy()
            
            # Convert to string to ensure it can be used as a dict key
            data_type_str = str(data_type) if data_type is not None else "unknown"
            
            if data_type_str == "all":
                return self.data.copy()
                
            return self.data_by_type.get(data_type_str, []).copy()
    
    def get_data_by_source(self, source):
        """
        Get data filtered by source.
        
        Args:
            source: Source of data to filter (str or list)
            
        Returns:
            List of data items matching the source
        """
        with self.lock:
            # Handle potential list input from Gradio
            if isinstance(source, list):
                if len(source) > 0:
                    source = source[0]
                else:
                    return self.data.copy()
            
            # Convert to string to ensure it can be used as a dict key
            source_str = str(source) if source is not None else "unknown"
            
            if source_str == "all":
                return self.data.copy()
                
            return self.data_by_source.get(source_str, []).copy()
    
    def get_data_by_timeframe(self, start_time, end_time=None):
        """Get data within a specific timeframe."""
        if end_time is None:
            end_time = time.time()
            
        with self.lock:
            return [item for item in self.data if start_time <= item.get("timestamp", 0) <= end_time]
    
    def get_metadata(self):
        """Get metadata about the collected data."""
        with self.lock:
            # Convert set to list for JSON serialization
            metadata = self.metadata.copy()
            metadata["types"] = list(metadata["types"])
            metadata["sources"] = list(metadata["sources"])
            
            # Format timestamps
            if metadata["first_timestamp"]:
                metadata["first_timestamp_formatted"] = time.strftime(
                    "%Y-%m-%d %H:%M:%S", time.localtime(metadata["first_timestamp"])
                )
            
            if metadata["last_timestamp"]:
                metadata["last_timestamp_formatted"] = time.strftime(
                    "%Y-%m-%d %H:%M:%S", time.localtime(metadata["last_timestamp"])
                )
                
            return metadata
    
    def clear_data(self):
        """Clear all collected data."""
        with self.lock:
            self.data = []
            self.data_by_type = {}
            self.data_by_source = {}
            self.data_by_timestamp = {}
            self.metadata = {
                "total_items": 0,
                "types": set(),
                "sources": set(),
                "first_timestamp": None,
                "last_timestamp": None
            }

# Create a custom log handler to capture extracted data
class ExtractedDataLogHandler(logging.Handler):
    def __init__(self):
        super().__init__()
        self.process_logs = []
        self.log_categories = {
            "agent_action": [],
            "agent_thought": [],
            "agent_memory": [],
            "agent_planning": [],
            "agent_evaluation": [],
            "agent_task_progress": [],
            "extracted_data": [],
            "error": [],
            "system": [],
            "other": []
        }
        self.max_logs = 5000  # Increased from 2000 to 5000 for more history
    
    def emit(self, record):
        log_entry = self.format(record)
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(record.created))
        
        # Create structured log entry
        structured_entry = {
            "timestamp": timestamp,
            "level": record.levelname,
            "logger": record.name,
            "message": log_entry,
            "source_file": record.pathname,
            "line_number": record.lineno,
            "step_number": None,  # Will be populated for step messages
            "raw_record": {
                "name": record.name,
                "levelname": record.levelname,
                "levelno": record.levelno,
                "pathname": record.pathname,
                "lineno": record.lineno,
                "msg": str(record.msg),
                "args": str(record.args),
                "exc_info": record.exc_info,
                "created": record.created
            }
        }
        
        # Store in process logs
        self.process_logs.append(structured_entry)
        
        # Categorize the log entry with enhanced detection
        if "Extracted from page" in log_entry and "```json" in log_entry:
            category = "extracted_data"
            # Extract the JSON part
            try:
                json_start = log_entry.find("```json") + 7
                json_end = log_entry.rfind("```")
                json_str = log_entry[json_start:json_end].strip()
                
                # Parse the JSON and add to the global list
                data_obj = json.loads(json_str)
                extracted_data_collector.add_data(data_obj)
                
                # Store the extracted JSON in the structured entry
                structured_entry["extracted_json"] = data_obj
            except Exception as e:
                logger.error(f"Error parsing extracted JSON: {str(e)}")
        elif record.levelname == "ERROR":
            category = "error"
        # Enhanced categorization with more specific categories
        elif "📍 Step" in log_entry and record.name == "src.agent.custom_agent":
            category = "agent_action"
            # Extract step number
            try:
                step_match = re.search(r"Step (\d+)", log_entry)
                if step_match:
                    structured_entry["step_number"] = int(step_match.group(1))
            except:
                pass
        elif "🤯 Start Deep Thinking" in log_entry or "🤯 End Deep Thinking" in log_entry:
            category = "agent_thought"
            structured_entry["thought_type"] = "deep_thinking"
        elif "🤯 Start Planning Deep Thinking" in log_entry or "🤯 End Planning Deep Thinking" in log_entry:
            category = "agent_planning"
            structured_entry["thought_type"] = "planning_deep_thinking"
        elif "🧠 All Memory" in log_entry:
            category = "agent_memory"
            # Extract memory content
            try:
                memory_content = log_entry.split("🧠 All Memory:")[1].strip()
                structured_entry["memory_content"] = memory_content
            except:
                structured_entry["memory_content"] = log_entry
        elif "🧠 New Memory" in log_entry:
            category = "agent_memory"
            structured_entry["memory_type"] = "new"
            # Extract memory content
            try:
                memory_content = log_entry.split("🧠 New Memory:")[1].strip()
                structured_entry["memory_content"] = memory_content
            except:
                structured_entry["memory_content"] = log_entry
        elif "⏳ Task Progress" in log_entry:
            category = "agent_task_progress"
            # Extract progress content
            try:
                progress_content = log_entry.split("⏳ Task Progress:")[1].strip()
                structured_entry["progress_content"] = progress_content
            except:
                structured_entry["progress_content"] = log_entry
        elif "📋 Future Plans" in log_entry or "📋 Plans" in log_entry:
            category = "agent_planning"
            # Extract planning content
            try:
                if "📋 Future Plans" in log_entry:
                    planning_content = log_entry.split("📋 Future Plans:")[1].strip()
                else:
                    planning_content = log_entry.split("📋 Plans:")[1].strip()
                structured_entry["planning_content"] = planning_content
            except:
                structured_entry["planning_content"] = log_entry
        elif "✅ Eval" in log_entry or "❌ Eval" in log_entry or "🤷 Eval" in log_entry:
            category = "agent_evaluation"
            # Extract evaluation status
            structured_entry["evaluation_status"] = "success" if "✅" in log_entry else ("failure" if "❌" in log_entry else "unknown")
            # Extract evaluation content
            try:
                eval_content = log_entry.split("Eval:")[1].strip()
                structured_entry["evaluation_content"] = eval_content
            except:
                structured_entry["evaluation_content"] = log_entry
        elif "🤔 Thought" in log_entry:
            category = "agent_thought"
            # Extract thought content
            try:
                thought_content = log_entry.split("🤔 Thought:")[1].strip()
                structured_entry["thought_content"] = thought_content
            except:
                structured_entry["thought_content"] = log_entry
        elif "🎯 Summary" in log_entry:
            category = "agent_thought"
            structured_entry["thought_type"] = "summary"
            # Extract summary content
            try:
                summary_content = log_entry.split("🎯 Summary:")[1].strip()
                structured_entry["summary_content"] = summary_content
            except:
                structured_entry["summary_content"] = log_entry
        elif "🛠️  Action" in log_entry:
            category = "agent_action"
            # Extract action details
            try:
                action_match = re.search(r"Action (\d+)/(\d+)", log_entry)
                if action_match:
                    structured_entry["action_number"] = int(action_match.group(1))
                    structured_entry["total_actions"] = int(action_match.group(2))
                action_content = log_entry.split(": ", 1)[1] if ": " in log_entry else log_entry
                structured_entry["action_content"] = action_content
            except:
                structured_entry["action_content"] = log_entry
        elif record.name.startswith("src.") or record.name.startswith("browser_use."):
            category = "system"
        else:
            category = "other"
        
        # Add to the appropriate category
        structured_entry["category"] = category
        self.log_categories[category].append(structured_entry)
        
        # Keep only the last max_logs messages to prevent memory issues
        if len(self.process_logs) > self.max_logs:
            self.process_logs = self.process_logs[-self.max_logs:]
            
        # Also trim category logs
        for cat in self.log_categories:
            if len(self.log_categories[cat]) > self.max_logs // 2:
                self.log_categories[cat] = self.log_categories[cat][-(self.max_logs // 2):]
    
    def get_process_logs(self):
        """Get all process logs as a single string."""
        return "\n".join([f"[{entry['timestamp']}] [{entry['level']}] {entry['message']}" for entry in self.process_logs])
    
    def get_logs_by_category(self, category):
        """
        Get logs for a specific category.
        
        Args:
            category: The category to filter by (string or list)
            
        Returns:
            String containing formatted log entries
        """
        try:
            # Handle potential list input
            if isinstance(category, list):
                if len(category) > 0:
                    category = category[0]
                else:
                    return self.get_process_logs()
            
            # Convert to string to ensure it can be used as a dict key
            category_str = str(category) if category is not None else "all"
            
            if category_str == "all":
                return self.get_process_logs()
                
            if category_str in self.log_categories:
                return "\n".join([
                    f"[{entry['timestamp']}] [{entry['level']}] {entry['message']}" 
                    for entry in self.log_categories[category_str]
                ])
            return ""
        except Exception as e:
            logging.error(f"Error getting logs by category: {str(e)}")
            return f"Error: {str(e)}"
    
    def get_logs_by_level(self, level):
        """
        Get logs filtered by log level.
        
        Args:
            level: The log level to filter by (string or list)
            
        Returns:
            String containing formatted log entries
        """
        try:
            # Handle potential list input
            if isinstance(level, list):
                if len(level) > 0:
                    level = level[0]
                else:
                    return self.get_process_logs()
            
            # Convert to string to ensure proper comparison
            level_str = str(level) if level is not None else "ALL"
            
            if level_str == "ALL":
                return self.get_process_logs()
                
            # Convert to uppercase for case-insensitive comparison
            level_upper = level_str.upper() if isinstance(level_str, str) else level_str
                
            filtered_logs = [
                entry for entry in self.process_logs 
                if entry['level'] == level_upper
            ]
            
            return "\n".join([
                f"[{entry['timestamp']}] [{entry['level']}] {entry['message']}" 
                for entry in filtered_logs
            ])
        except Exception as e:
            logging.error(f"Error getting logs by level: {str(e)}")
            return f"Error: {str(e)}"
    
    def search_logs(self, search_term):
        """
        Search logs for a specific term.
        
        Args:
            search_term: The term to search for (string or list)
            
        Returns:
            String containing formatted log entries matching the search
        """
        try:
            # Handle potential list input
            if isinstance(search_term, list):
                if len(search_term) > 0:
                    search_term = search_term[0]
                else:
                    return self.get_process_logs()
                    
            # Convert to string to ensure proper searching
            search_str = str(search_term) if search_term is not None else ""
            
            if not search_str:
                return self.get_process_logs()
                
            # Convert to lowercase for case-insensitive search
            search_lower = search_str.lower() if isinstance(search_str, str) else search_str
                
            filtered_logs = [
                entry for entry in self.process_logs 
                if search_lower in str(entry.get('message', '')).lower()
            ]
            
            return "\n".join([
                f"[{entry['timestamp']}] [{entry['level']}] {entry['message']}" 
                for entry in filtered_logs
            ])
        except Exception as e:
            logging.error(f"Error searching logs: {str(e)}")
            return f"Error: {str(e)}"
    
    def get_stats(self):
        """Get statistics about the logs."""
        stats = {
            "total_logs": len(self.process_logs),
            "by_category": {cat: len(logs) for cat, logs in self.log_categories.items()},
            "by_level": {}
        }
        
        # Count logs by level
        for entry in self.process_logs:
            level = entry['level']
            if level not in stats["by_level"]:
                stats["by_level"][level] = 0
            stats["by_level"][level] += 1
            
        return stats
    
    def clear_logs(self):
        """Clear all process logs."""
        self.process_logs = []
        for category in self.log_categories:
            self.log_categories[category] = []

# Create a custom log handler to capture terminal output
class TerminalLogHandler(logging.Handler):
    def __init__(self, data_collector):
        super().__init__()
        self.data_collector = data_collector
    
    def emit(self, record):
        log_entry = self.format(record)
        # Add the log entry to the data collector
        self.data_collector.add_data({
            "type": "terminal_log",
            "message": log_entry,
            "level": record.levelname,
            "timestamp": record.created
        })
        
        # Also add to agent tracker for inclusion in JSON export
        try:
            tracker = get_agent_tracker()
            if tracker:
                tracker.add_terminal_log(log_entry)
        except Exception as e:
            # Don't let errors in tracking disrupt logging
            pass

# Create global instances for data collection and logging
extracted_data_collector = ExtractedDataCollector()
data_log_handler = ExtractedDataLogHandler()

# Function to get or create the global agent tracker (prevents order dependency)
_agent_tracker_instance = None
def get_agent_tracker():
    """Get or create the global AgentTracker instance"""
    global _agent_tracker_instance
    if _agent_tracker_instance is None:
        # Use the AgentTracker class defined in this file
        _agent_tracker_instance = AgentTracker()
    return _agent_tracker_instance

# Custom log interceptor to feed data to the agent tracker
class AgentTrackerLogHandler(logging.Handler):
    def __init__(self):
        super().__init__()
        self.setLevel(logging.INFO)
        
    def emit(self, record):
        try:
            log_entry = self.format(record)
            
            # Only process agent-related logs
            if record.name != 'src.agent.custom_agent':
                return
                
            # Extract action data
            if "🛠️  Action" in log_entry:
                try:
                    # Parse action details from log
                    action_parts = log_entry.split("🛠️  Action")[1].strip()
                    action_num = action_parts.split("/")[0].strip()
                    action_content = action_parts.split(":", 1)[1].strip() if ":" in action_parts else action_parts
                    
                    # Track the action
                    get_agent_tracker().track_action({
                        "action_type": "browser_action",
                        "action_number": action_num,
                        "content": action_content,
                        "raw_log": log_entry
                    })
                except Exception as e:
                    logging.error(f"Error tracking action: {str(e)}")
            
            # Extract thought data
            elif "🤔 Thought" in log_entry:
                try:
                    thought_content = log_entry.split("🤔 Thought:")[1].strip()
                    get_agent_tracker().track_thought({
                        "thought_type": "reasoning",
                        "content": thought_content,
                        "raw_log": log_entry
                    })
                except Exception as e:
                    logging.error(f"Error tracking thought: {str(e)}")
            
            # Extract memory data
            elif "🧠 New Memory" in log_entry:
                try:
                    memory_content = log_entry.split("🧠 New Memory:")[1].strip()
                    get_agent_tracker().track_memory({
                        "memory_type": "new",
                        "content": memory_content,
                        "raw_log": log_entry
                    })
                except Exception as e:
                    logging.error(f"Error tracking memory: {str(e)}")
            
            # Extract evaluation data
            elif "Eval:" in log_entry:
                try:
                    success = "✅" in log_entry
                    failed = "❌" in log_entry
                    eval_content = log_entry.split("Eval:")[1].strip()
                    
                    get_agent_tracker().track_evaluation({
                        "success": success,
                        "failed": failed,
                        "content": eval_content,
                        "raw_log": log_entry
                    })
                except Exception as e:
                    logging.error(f"Error tracking evaluation: {str(e)}")
            
            # Extract planning data
            elif "📋 Future Plans" in log_entry:
                try:
                    plan_content = log_entry.split("📋 Future Plans:")[1].strip()
                    get_agent_tracker().track_plan({
                        "plan_type": "future",
                        "content": plan_content,
                        "raw_log": log_entry
                    })
                except Exception as e:
                    logging.error(f"Error tracking plan: {str(e)}")
            
            # Extract step information to track progress
            elif "📍 Step" in log_entry:
                try:
                    step_match = re.search(r"Step (\d+)", log_entry)
                    if step_match:
                        step_num = int(step_match.group(1))
                        get_agent_tracker().track_action({
                            "action_type": "step_transition",
                            "step": step_num,
                            "raw_log": log_entry
                        })
                except Exception as e:
                    logging.error(f"Error tracking step: {str(e)}")
                    
        except Exception as e:
            logging.error(f"Error in AgentTrackerLogHandler: {str(e)}")

# Create a handler for the agent tracker
agent_tracker_handler = AgentTrackerLogHandler()
agent_tracker_handler.setFormatter(logging.Formatter('%(message)s'))
logging.getLogger('src.agent.custom_agent').addHandler(agent_tracker_handler)

# Add the data handler to relevant loggers
controller_logger = logging.getLogger('controller')
controller_logger.addHandler(data_log_handler)

# Set up the terminal log handler
terminal_logger = logging.getLogger()
terminal_logger.setLevel(logging.INFO)
terminal_log_handler = TerminalLogHandler(extracted_data_collector)
terminal_log_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
terminal_logger.addHandler(terminal_log_handler)

# Add a stream handler to output logs to the terminal
stream_handler = logging.StreamHandler()
stream_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
stream_handler.setLevel(logging.INFO)
terminal_logger.addHandler(stream_handler)

# Function to log messages to both terminal and data collector
def log_message(message, level="INFO"):
    """Log a message to both terminal and data collector."""
    if level.upper() == "INFO":
        logging.info(message)
    elif level.upper() == "WARNING":
        logging.warning(message)
    elif level.upper() == "ERROR":
        logging.error(message)
    elif level.upper() == "DEBUG":
        logging.debug(message)
    else:
        logging.info(message)
    
    # Also add directly to data collector for immediate display
    extracted_data_collector.add_data({
        "type": "direct_log",
        "message": message,
        "level": level,
        "timestamp": time.time()
    })

load_dotenv()
import os
import glob
import asyncio
import argparse
import os

logger = logging.getLogger(__name__)

# Add the handler to the root logger and other relevant loggers
root_logger = logging.getLogger()
root_logger.addHandler(data_log_handler)

# Also add to specific loggers that might be used by the agent
agent_logger = logging.getLogger('agent')
agent_logger.addHandler(data_log_handler)
browser_logger = logging.getLogger('browser_use')
browser_logger.addHandler(data_log_handler)
controller_logger = logging.getLogger('controller')
controller_logger.addHandler(data_log_handler)
src_agent_logger = logging.getLogger('src.agent.custom_agent')
src_agent_logger.addHandler(data_log_handler)

import gradio as gr
from gradio import themes

from browser_use.agent.service import Agent
from playwright.async_api import async_playwright
from browser_use.browser.browser import Browser, BrowserConfig
from browser_use.browser.context import (
    BrowserContextConfig,
    BrowserContextWindowSize,
)
from langchain_ollama import ChatOllama
from playwright.async_api import async_playwright
from src.utils.agent_state import AgentState

from src.utils import utils
from src.agent.custom_agent import CustomAgent
from src.browser.custom_browser import CustomBrowser
from src.agent.custom_prompts import CustomSystemPrompt, CustomAgentMessagePrompt
from src.browser.custom_context import BrowserContextConfig, CustomBrowserContext
from src.controller.custom_controller import CustomController
from gradio.themes import Citrus, Default, Glass, Monochrome, Ocean, Origin, Soft, Base
from src.utils.default_config_settings import default_config, load_config_from_file, save_config_to_file, save_current_config, update_ui_from_config
from src.utils.utils import update_model_dropdown, get_latest_files, capture_screenshot, save_task, load_tasks, delete_task
from src.utils.playlist_utils import (
    load_saved_playlists_for_ui,
    load_selected_playlist_for_ui,
    save_current_playlist_for_ui,
    delete_selected_playlist_for_ui,
    add_task_to_playlist_for_ui,
    remove_task_from_playlist_for_ui,
    move_task_up_for_ui,
    move_task_down_for_ui,
    update_available_tasks_for_ui,
    play_playlist_for_ui
)

# Ensure default_config includes 'add_infos'
def get_config_with_add_infos():
    """Get the default config and ensure it has the 'add_infos' key."""
    config = default_config()
    if 'add_infos' not in config:
        config['add_infos'] = ""  # Add with empty string as default value
    return config

# Global variables for persistence
_global_browser = None
_global_browser_context = None
_global_agent = None

# Create the global agent state instance
_global_agent_state = AgentState()

# Global variable to store extracted data
extracted_data = []
extracted_data_lock = threading.Lock()

def add_extracted_data(data_obj):
    """Add extracted data to the collector."""
    global extracted_data_collector
    return extracted_data_collector.add_data(data_obj)

def get_extracted_data():
    """Get all collected data."""
    global extracted_data_collector
    return extracted_data_collector.get_data()

def clear_extracted_data():
    """Clear all collected data."""
    global extracted_data_collector
    extracted_data_collector.clear_data()
    return []

def resolve_sensitive_env_variables(text):
    """
    Replace environment variable placeholders ($SENSITIVE_*) with their values.
    Only replaces variables that start with SENSITIVE_.
    """
    if not text:
        return text
        
    import re
    
    # Find all $SENSITIVE_* patterns
    env_vars = re.findall(r'\$SENSITIVE_[A-Za-z0-9_]*', text)
    
    result = text
    for var in env_vars:
        # Remove the $ prefix to get the actual environment variable name
        env_name = var[1:]  # removes the $
        env_value = os.getenv(env_name)
        if env_value is not None:
            # Replace $SENSITIVE_VAR_NAME with its value
            result = result.replace(var, env_value)
        
    return result

async def stop_agent():
    """Request the agent to stop and update UI with enhanced feedback"""
    global _global_agent_state, _global_browser_context, _global_browser, _global_agent

    try:
        # Request stop
        if _global_agent is not None:
                _global_agent.stop()

        # Update UI immediately
        message = "Stop requested - the agent will halt at the next safe point"
        logger.info(f"🛑 {message}")

        # Return UI updates
        return (
            message,                                        # errors_output
            gr.update(value="Stopping...", interactive=False),  # stop_button
            gr.update(interactive=False),                      # run_button
        )
    except Exception as e:
        error_msg = f"Error during stop: {str(e)}"
        logger.error(error_msg)
        return (
            error_msg,
            gr.update(value="Stop", interactive=True),
            gr.update(interactive=True)
        )
        
async def stop_research_agent():
    """Request the agent to stop and update UI with enhanced feedback"""
    global _global_agent_state, _global_browser_context, _global_browser

    try:
        # Request stop
        _global_agent_state.request_stop()

        # Update UI immediately
        message = "Stop requested - the agent will halt at the next safe point"
        logger.info(f"🛑 {message}")

        # Return UI updates
        return (                                   # errors_output
            gr.update(value="Stopping...", interactive=False),  # stop_button
            gr.update(interactive=False),                      # run_button
        )
    except Exception as e:
        error_msg = f"Error during stop: {str(e)}"
        logger.error(error_msg)
        return (
            gr.update(value="Stop", interactive=True),
            gr.update(interactive=True)
        )

async def run_browser_agent(
        agent_type,
        llm_provider,
        llm_model_name,
        llm_num_ctx,
        llm_temperature,
        llm_base_url,
        llm_api_key,
        use_own_browser,
        keep_browser_open,
        headless,
        disable_security,
        window_w,
        window_h,
        save_recording_path,
        save_agent_history_path,
        save_trace_path,
        enable_recording,
        task,
        add_infos,
        max_steps,
        use_vision,
        max_actions_per_step,
        tool_calling_method
):
    """Run the browser agent with the specified parameters."""
    global _global_browser, _global_browser_context, _global_agent_state, _global_agent
    
    # Log the start of the agent
    log_message(f"Starting {agent_type} agent with task: {task}")
    
    # Check if an agent is already running
    if _global_agent is not None:
        log_message("An agent is already running. Please stop it first.", "ERROR")
        return "An agent is already running. Please stop it first."
    
    _global_agent_state.clear_stop()  # Clear any previous stop requests

    try:
        # Disable recording if the checkbox is unchecked
        if not enable_recording:
            save_recording_path = None

        # Ensure the recording directory exists if recording is enabled
        if save_recording_path:
            os.makedirs(save_recording_path, exist_ok=True)

        # Get the list of existing videos before the agent runs
        existing_videos = set()
        if save_recording_path:
            existing_videos = set(
                glob.glob(os.path.join(save_recording_path, "*.[mM][pP]4"))
                + glob.glob(os.path.join(save_recording_path, "*.[wW][eE][bB][mM]"))
            )

        task = resolve_sensitive_env_variables(task)

        # Run the agent
        llm = utils.get_llm_model(
            provider=llm_provider,
            model_name=llm_model_name,
            num_ctx=llm_num_ctx,
            temperature=llm_temperature,
            base_url=llm_base_url,
            api_key=llm_api_key,
        )
        if agent_type == "org":
            final_result, errors, model_actions, model_thoughts, trace_file, history_file = await run_org_agent(
                llm=llm,
                use_own_browser=use_own_browser,
                keep_browser_open=keep_browser_open,
                headless=headless,
                disable_security=disable_security,
                window_w=window_w,
                window_h=window_h,
                save_recording_path=save_recording_path,
                save_agent_history_path=save_agent_history_path,
                save_trace_path=save_trace_path,
                task=task,
                max_steps=max_steps,
                use_vision=use_vision,
                max_actions_per_step=max_actions_per_step,
                tool_calling_method=tool_calling_method
            )
        elif agent_type == "custom":
            final_result, errors, model_actions, model_thoughts, trace_file, history_file = await run_custom_agent(
                llm=llm,
                use_own_browser=use_own_browser,
                keep_browser_open=keep_browser_open,
                headless=headless,
                disable_security=disable_security,
                window_w=window_w,
                window_h=window_h,
                save_recording_path=save_recording_path,
                save_agent_history_path=save_agent_history_path,
                save_trace_path=save_trace_path,
                task=task,
                add_infos=add_infos,
                max_steps=max_steps,
                use_vision=use_vision,
                max_actions_per_step=max_actions_per_step,
                tool_calling_method=tool_calling_method
            )
        else:
            raise ValueError(f"Invalid agent type: {agent_type}")

        # Get the list of videos after the agent runs (if recording is enabled)
        latest_video = None
        if save_recording_path:
            new_videos = set(
                glob.glob(os.path.join(save_recording_path, "*.[mM][pP]4"))
                + glob.glob(os.path.join(save_recording_path, "*.[wW][eE][bB][mM]"))
            )
            if new_videos - existing_videos:
                latest_video = list(new_videos - existing_videos)[0]  # Get the first new video

        return (
            final_result,
            errors,
            model_actions,
            model_thoughts,
            latest_video,
            trace_file,
            history_file,
            gr.update(value="Stop", interactive=True),  # Re-enable stop button
            gr.update(interactive=True)    # Re-enable run button
        )

    except gr.Error:
        raise

    except Exception as e:
        import traceback
        traceback.print_exc()
        errors = str(e) + "\n" + traceback.format_exc()
        return (
            '',                                         # final_result
            errors,                                     # errors
            '',                                         # model_actions
            '',                                         # model_thoughts
            None,                                       # latest_video
            None,                                       # history_file
            None,                                       # trace_file
            gr.update(value="Stop", interactive=True),  # Re-enable stop button
            gr.update(interactive=True)    # Re-enable run button
        )


async def run_org_agent(
        llm,
        use_own_browser,
        keep_browser_open,
        headless,
        disable_security,
        window_w,
        window_h,
        save_recording_path,
        save_agent_history_path,
        save_trace_path,
        task,
        max_steps,
        use_vision,
        max_actions_per_step,
        tool_calling_method
):
    try:
        global _global_browser, _global_browser_context, _global_agent_state, _global_agent
        
        # Clear any previous stop request
        _global_agent_state.clear_stop()

        extra_chromium_args = [f"--window-size={window_w},{window_h}"]
        if use_own_browser:
            chrome_path = os.getenv("CHROME_PATH", None)
            if chrome_path == "":
                chrome_path = None
            chrome_user_data = os.getenv("CHROME_USER_DATA", None)
            if chrome_user_data:
                extra_chromium_args += [f"--user-data-dir={chrome_user_data}"]
        else:
            chrome_path = None
            
        if _global_browser is None:
            _global_browser = Browser(
                config=BrowserConfig(
                    headless=headless,
                    disable_security=disable_security,
                    chrome_instance_path=chrome_path,
                    extra_chromium_args=extra_chromium_args,
                )
            )

        if _global_browser_context is None:
            _global_browser_context = await _global_browser.new_context(
                config=BrowserContextConfig(
                    trace_path=save_trace_path if save_trace_path else None,
                    save_recording_path=save_recording_path if save_recording_path else None,
                    no_viewport=False,
                    browser_window_size=BrowserContextWindowSize(
                        width=window_w, height=window_h
                    ),
                )
            )

        if _global_agent is None:
            _global_agent = Agent(
                task=task,
                llm=llm,
                use_vision=use_vision,
                browser=_global_browser,
                browser_context=_global_browser_context,
                max_actions_per_step=max_actions_per_step,
                tool_calling_method=tool_calling_method
            )
        history = await _global_agent.run(max_steps=max_steps)

        history_file = os.path.join(save_agent_history_path, f"{_global_agent.agent_id}.json")
        _global_agent.save_history(history_file)

        final_result = history.final_result()
        errors = history.errors()
        model_actions = history.model_actions()
        model_thoughts = history.model_thoughts()

        trace_file = get_latest_files(save_trace_path)

        return final_result, errors, model_actions, model_thoughts, trace_file.get('.zip'), history_file
    except Exception as e:
        import traceback
        traceback.print_exc()
        errors = str(e) + "\n" + traceback.format_exc()
        return '', errors, '', '', None, None
    finally:
        _global_agent = None
        # Handle cleanup based on persistence configuration
        if not keep_browser_open:
            if _global_browser_context:
                await _global_browser_context.close()
                _global_browser_context = None

            if _global_browser:
                await _global_browser.close()
                _global_browser = None

async def run_custom_agent(
        llm,
        use_own_browser,
        keep_browser_open,
        headless,
        disable_security,
        window_w,
        window_h,
        save_recording_path,
        save_agent_history_path,
        save_trace_path,
        task,
        add_infos,
        max_steps,
        use_vision,
        max_actions_per_step,
        tool_calling_method
):
    try:
        global _global_browser, _global_browser_context, _global_agent_state, _global_agent

        # Clear any previous stop request
        if _global_agent_state is not None:
            _global_agent_state.clear_stop()

        extra_chromium_args = [f"--window-size={window_w},{window_h}"]
        if use_own_browser:
            chrome_path = os.getenv("CHROME_PATH", None)
            if chrome_path == "":
                chrome_path = None
            chrome_user_data = os.getenv("CHROME_USER_DATA", None)
            if chrome_user_data:
                extra_chromium_args += [f"--user-data-dir={chrome_user_data}"]
        else:
            chrome_path = None

        controller = CustomController()

        # Initialize global browser if needed
        if _global_browser is None:
            _global_browser = CustomBrowser(
                config=BrowserConfig(
                    headless=headless,
                    disable_security=disable_security,
                    chrome_instance_path=chrome_path,
                    extra_chromium_args=extra_chromium_args,
                )
            )

        if _global_browser_context is None:
            _global_browser_context = await _global_browser.new_context(
                config=BrowserContextConfig(
                    trace_path=save_trace_path if save_trace_path else None,
                    save_recording_path=save_recording_path if save_recording_path else None,
                    no_viewport=False,
                    browser_window_size=BrowserContextWindowSize(
                        width=window_w, height=window_h
                    ),
                )
            )
            
        # Create and run agent
        if _global_agent is None:
            _global_agent = CustomAgent(
                task=task,
                add_infos=add_infos,
                use_vision=use_vision,
                llm=llm,
                browser=_global_browser,
                browser_context=_global_browser_context,
                controller=controller,
                system_prompt_class=CustomSystemPrompt,
                agent_prompt_class=CustomAgentMessagePrompt,
                max_actions_per_step=max_actions_per_step,
                tool_calling_method=tool_calling_method
            )
        history = await _global_agent.run(max_steps=max_steps)

        # Create a sanitized task name for the filename (remove special characters)
        import re
        import datetime
        
        # Get the first 50 characters of the task and sanitize it for filename use
        task_short = task[:50] if task else "unknown_task"
        task_sanitized = re.sub(r'[^\w\s-]', '', task_short).strip().replace(' ', '_')
        
        # Get current timestamp
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Create descriptive filename with task name, timestamp, and agent ID
        descriptive_filename = f"{task_sanitized}_{timestamp}_{_global_agent.agent_id}.json"
        
        # Save with original UUID filename for compatibility
        original_history_file = os.path.join(save_agent_history_path, f"{_global_agent.agent_id}.json")
        _global_agent.save_history(original_history_file)
        
        # Also save with descriptive filename
        descriptive_history_file = os.path.join(save_agent_history_path, descriptive_filename)
        _global_agent.save_history(descriptive_history_file)
        
        # Auto-export the history file to user's downloads
        auto_export_history(descriptive_history_file)

        final_result = history.final_result()
        errors = history.errors()
        model_actions = history.model_actions()
        model_thoughts = history.model_thoughts()

        trace_file = get_latest_files(save_trace_path)        

        # Return the descriptive filename for display in the UI
        return final_result, errors, model_actions, model_thoughts, trace_file.get('.zip'), descriptive_history_file
    except Exception as e:
        import traceback
        traceback.print_exc()
        errors = str(e) + "\n" + traceback.format_exc()
        return '', errors, '', '', None, None
    finally:
        _global_agent = None
        # Handle cleanup based on persistence configuration
        if not keep_browser_open:
            if _global_browser_context:
                await _global_browser_context.close()
                _global_browser_context = None

            if _global_browser:
                await _global_browser.close()
                _global_browser = None

# Add a function to automatically export the agent history
def auto_export_history(history_file_path):
    """
    Automatically export the agent history file to the user's downloads directory.
    
    Args:
        history_file_path (str): Path to the agent history file
    
    Returns:
        str: Path to the exported file or error message
    """
    if not history_file_path or not os.path.exists(history_file_path):
        logging.warning("No agent history file available to auto-export.")
        return None
    
    try:
        # Get the filename from the path
        filename = os.path.basename(history_file_path)
        
        # Create a user downloads directory if it doesn't exist
        user_downloads = os.path.expanduser("~/Downloads/browser-use-exports")
        os.makedirs(user_downloads, exist_ok=True)
        
        # Copy the file to the user's downloads directory
        export_path = os.path.join(user_downloads, filename)
        shutil.copy2(history_file_path, export_path)
        
        logging.info(f"Agent history auto-exported to: {export_path}")
        return export_path
    except Exception as e:
        logging.error(f"Error auto-exporting agent history: {str(e)}")
        return None

async def run_with_stream(
    agent_type,
    llm_provider,
    llm_model_name,
    llm_num_ctx,
    llm_temperature,
    llm_base_url,
    llm_api_key,
    use_own_browser,
    keep_browser_open,
    headless,
    disable_security,
    window_w,
    window_h,
    save_recording_path,
    save_agent_history_path,
    save_trace_path,
    enable_recording,
    task,
    add_infos,
    max_steps,
    use_vision,
    max_actions_per_step,
    tool_calling_method
):
    global _global_agent_state
    stream_vw = 80
    stream_vh = int(80 * window_h // window_w)
    
    # Log the start of the streaming process
    log_message(f"Starting agent with streaming output for task: {task}")
    
    # Clear the logs at the start of a new run
    data_log_handler.clear_logs()
    extracted_data_collector.clear_data()
    
    # Create a function to update the process log
    def update_logs():
        process_logs = data_log_handler.get_process_logs()
        return process_logs
    
    if not headless:
        log_message("Running in non-headless mode")
        result = await run_browser_agent(
            agent_type=agent_type,
            llm_provider=llm_provider,
            llm_model_name=llm_model_name,
            llm_num_ctx=llm_num_ctx,
            llm_temperature=llm_temperature,
            llm_base_url=llm_base_url,
            llm_api_key=llm_api_key,
            use_own_browser=use_own_browser,
            keep_browser_open=keep_browser_open,
            headless=headless,
            disable_security=disable_security,
            window_w=window_w,
            window_h=window_h,
            save_recording_path=save_recording_path,
            save_agent_history_path=save_agent_history_path,
            save_trace_path=save_trace_path,
            enable_recording=enable_recording,
            task=task,
            add_infos=add_infos,
            max_steps=max_steps,
            use_vision=use_vision,
            max_actions_per_step=max_actions_per_step,
            tool_calling_method=tool_calling_method
        )
        # Add HTML content at the start of the result array
        html_content = f"<h1 style='width:{stream_vw}vw; height:{stream_vh}vh'>Using browser...</h1>"
        
        # Get the extracted data
        extracted_data = extracted_data_collector.get_data()
        
        # Get the process logs
        process_logs = update_logs()
        
        # Insert the extracted data into the result
        result_list = list(result)
        result_list.insert(1, extracted_data)  # Insert extracted data after html_content
        
        log_message("Agent completed execution in non-headless mode")
        
        # Add process logs to the result
        yield [html_content] + result_list + [process_logs]
    else:
        log_message("Running in headless mode")
        try:
            _global_agent_state.clear_stop()
            # Run the browser agent in the background
            agent_task = asyncio.create_task(
                run_browser_agent(
                    agent_type=agent_type,
                    llm_provider=llm_provider,
                    llm_model_name=llm_model_name,
                    llm_num_ctx=llm_num_ctx,
                    llm_temperature=llm_temperature,
                    llm_base_url=llm_base_url,
                    llm_api_key=llm_api_key,
                    use_own_browser=use_own_browser,
                    keep_browser_open=keep_browser_open,
                    headless=headless,
                    
                    disable_security=disable_security,
                    window_w=window_w,
                    window_h=window_h,
                    save_agent_history_path=save_agent_history_path,
                    save_trace_path=save_trace_path,
                    enable_recording=enable_recording,
                    task=task,
                    add_infos=add_infos,
                    max_steps=max_steps,
                    use_vision=use_vision,
                    max_actions_per_step=max_actions_per_step,
                    tool_calling_method=tool_calling_method
                )
            )
            result = await agent_task
            # Get the process logs
            process_logs = update_logs()
            
            log_message("Agent completed execution in headless mode")
            yield result + [process_logs]
        except Exception as e:
            log_message(f"Error during headless execution: {str(e)}")
            yield (
                '',                                         # final_result
                f"Error during headless execution: {str(e)}",  # errors
                '',                                         # model_actions
                '',                                         # model_thoughts
                None,                                       # latest_video
                None,                                       # history_file
                None,                                       # trace_file
                gr.update(value="Stop", interactive=True),      # Re-enable stop button
                gr.update(interactive=True),                   # Re-enable run button
                ''                                          # process_logs
            )

# Define the theme map globally
theme_map = {
    "Default": Default,
    "Soft": Soft,
    "Monochrome": Monochrome,
    "Glass": Glass,
    "Origin": Origin,
    "Citrus": Citrus,
    "Ocean": Ocean,
    "Base": Base
}

async def close_global_browser():
    global _global_browser, _global_browser_context

    if _global_browser_context:
        await _global_browser_context.close()
        _global_browser_context = None

    if _global_browser:
        await _global_browser.close()
        _global_browser = None
        
async def run_deep_search(research_task, max_search_iteration_input, max_query_per_iter_input, llm_provider, llm_model_name, llm_num_ctx, llm_temperature, llm_base_url, llm_api_key, use_vision, use_own_browser, headless):
    from src.utils.deep_research import deep_research
    global _global_agent_state

    # Clear any previous stop request
    _global_agent_state.clear_stop()
    
    llm = utils.get_llm_model(
            provider=llm_provider,
            model_name=llm_model_name,
            num_ctx=llm_num_ctx,
            temperature=llm_temperature,
            base_url=llm_base_url,
            api_key=llm_api_key,
        )
    markdown_content, file_path = await deep_research(research_task, llm, _global_agent_state,
                                                        max_search_iterations=max_search_iteration_input,
                                                        max_query_num=max_query_per_iter_input,
                                                        use_vision=use_vision,
                                                        headless=headless,
                                                        use_own_browser=use_own_browser
                                                        )
    
    return markdown_content, file_path, gr.update(value="Stop", interactive=True),  gr.update(interactive=True) 
    

def create_ui(config, theme_name="Ocean"):
    # Get the theme class
    theme_instance = theme_name
    
    css = """
    /* Custom CSS */
    .gradio-container {
        max-width: 1400px !important;
        margin-left: auto !important;
        margin-right: auto !important;
    }
    
    /* Make JSON component wider */
    .json-component {
        width: 100% !important;
        max-width: 100% !important;
    }
    
    /* Improve JSON formatting */
    .json-component pre {
        white-space: pre-wrap !important;
        word-break: break-word !important;
        font-size: 14px !important;
        line-height: 1.5 !important;
    }
    """

    with gr.Blocks(
            title="Browser Use WebUI", theme=theme_instance, css=css
    ) as demo:
        with gr.Row():
            gr.Markdown(
                """
                # 🌐 Browser Use WebUI
                ### Control your browser with AI assistance
                """,
                elem_classes=["header-text"],
            )

        with gr.Tabs() as tabs:
            with gr.TabItem("⚙️ Agent Settings", id=1):
                with gr.Group():
                    agent_type = gr.Radio(
                        ["org", "custom"],
                        label="Agent Type",
                        value=config['agent_type'],
                        info="Select the type of agent to use",
                    )
                    with gr.Column():
                        max_steps = gr.Slider(
                            minimum=1,
                            maximum=200,
                            value=config['max_steps'],
                            step=1,
                            label="Max Run Steps",
                            info="Maximum number of steps the agent will take",
                        )
                        max_actions_per_step = gr.Slider(
                            minimum=1,
                            maximum=20,
                            value=config['max_actions_per_step'],
                            step=1,
                            label="Max Actions per Step",
                            info="Maximum number of actions the agent will take per step",
                        )
                    with gr.Column():
                        use_vision = gr.Checkbox(
                            label="Use Vision",
                            value=config['use_vision'],
                            info="Enable visual processing capabilities",
                        )
                        tool_calling_method = gr.Dropdown(
                            label="Tool Calling Method",
                            value=config['tool_calling_method'],
                            interactive=True,
                            allow_custom_value=True,  # Allow users to input custom model names
                            choices=["auto", "json_schema", "function_calling"],
                            info="Tool Calls Funtion Name",
                            visible=False
                        )

            with gr.TabItem("🔧 LLM Configuration", id=2):
                with gr.Group():
                    llm_provider = gr.Dropdown(
                        choices=[provider for provider,model in utils.model_names.items()],
                        label="LLM Provider",
                        value=config['llm_provider'],
                        info="Select your preferred language model provider"
                    )
                    llm_model_name = gr.Dropdown(
                        label="Model Name",
                        choices=utils.model_names['openai'],
                        value=config['llm_model_name'],
                        interactive=True,
                        allow_custom_value=True,  # Allow users to input custom model names
                        info="Select a model from the dropdown or type a custom model name"
                    )
                    llm_num_ctx = gr.Slider(
                        minimum=2**8,
                        maximum=2**16,
                        value=config['llm_num_ctx'],
                        step=1,
                        label="Max Context Length",
                        info="Controls max context length model needs to handle (less = faster)",
                        visible=config['llm_provider'] == "ollama"
                    )
                    llm_temperature = gr.Slider(
                        minimum=0.0,
                        maximum=2.0,
                        value=config['llm_temperature'],
                        step=0.1,
                        label="Temperature",
                        info="Controls randomness in model outputs"
                    )
                    with gr.Row():
                        llm_base_url = gr.Textbox(
                            label="Base URL",
                            value=config['llm_base_url'],
                            info="API endpoint URL (if required)"
                        )
                        llm_api_key = gr.Textbox(
                            label="API Key",
                            type="password",
                            value=config['llm_api_key'],
                            info="Your API key (leave blank to use .env)"
                        )

            # Change event to update context length slider
            def update_llm_num_ctx_visibility(llm_provider):
                return gr.update(visible=llm_provider == "ollama")

            # Bind the change event of llm_provider to update the visibility of context length slider
            llm_provider.change(
                fn=update_llm_num_ctx_visibility,
                inputs=llm_provider,
                outputs=llm_num_ctx
            )

            with gr.TabItem("🌐 Browser Settings", id=3):
                with gr.Group():
                    with gr.Row():
                        use_own_browser = gr.Checkbox(
                            label="Use Own Browser",
                            value=config['use_own_browser'],
                            info="Use your existing browser instance",
                        )
                        keep_browser_open = gr.Checkbox(
                            label="Keep Browser Open",
                            value=config['keep_browser_open'],
                            info="Keep Browser Open between Tasks",
                        )
                        headless = gr.Checkbox(
                            label="Headless Mode",
                            value=config['headless'],
                            info="Run browser without GUI",
                        )
                        disable_security = gr.Checkbox(
                            label="Disable Security",
                            value=config['disable_security'],
                            info="Disable browser security features",
                        )
                        enable_recording = gr.Checkbox(
                            label="Enable Recording",
                            value=config['enable_recording'],
                            info="Enable saving browser recordings",
                        )

                    with gr.Row():
                        window_w = gr.Number(
                            label="Window Width",
                            value=config['window_w'],
                            info="Browser window width",
                        )
                        window_h = gr.Number(
                            label="Window Height",
                            value=config['window_h'],
                            info="Browser window height",
                        )

                    save_recording_path = gr.Textbox(
                        label="Recording Path",
                        placeholder="e.g. ./tmp/record_videos",
                        value=config['save_recording_path'],
                        info="Path to save browser recordings",
                        interactive=True,  # Allow editing only if recording is enabled
                    )

                    save_trace_path = gr.Textbox(
                        label="Trace Path",
                        placeholder="e.g. ./tmp/traces",
                        value=config['save_trace_path'],
                        info="Path to save Agent traces",
                        interactive=True,
                    )

                    save_agent_history_path = gr.Textbox(
                        label="Agent History Save Path",
                        placeholder="e.g., ./tmp/agent_history",
                        value=config['save_agent_history_path'],
                        info="Specify the directory where agent history should be saved.",
                        interactive=True,
                    )

            with gr.TabItem("🤖 Run Agent", id=4):
                # Add task template dropdown at the top
                with gr.Row():
                    with gr.Column(scale=2):
                        task = gr.Textbox(
                            label="Task",
                            lines=5,
                            value=config["task"],
                            info="Describe the task for the agent to perform",
                        )
                        add_infos = gr.Textbox(
                            label="Additional Information", 
                            info="Any additional context or instructions", 
                            lines=4
                        )
                        refresh_templates_button = gr.Button("🔄 Refresh", scale=1)
                        
                # Add feedback message
                task_feedback = gr.Textbox(label="", visible=False)
                
                with gr.Row():
                    with gr.Column(scale=2):
                                task = gr.Textbox(
                            label="Task",
                            lines=5,
                            value=config['task'],
                                    info="Describe the task for the agent to perform",
                        )
                    add_infos = gr.Textbox(
                            label="Additional Information",
                            lines=3,
                            value=config['add_infos'],
                            info="Optional: Provide additional context or instructions",
                        )
                        
                        # Add live log for extracted data directly on the Run Agent tab
                    with gr.Accordion("📋 Live Data Log", open=True):
                            extracted_data_log = gr.JSON(
                                label="Extracted Data",
                                show_label=True,
                                elem_id="extracted_data_log",
                                value=extracted_data_collector.get_data(),  # Initialize with current data
                                height=500,  # Make the box taller
                                container=True,  # Add container styling
                            )
                            
                            # Add custom CSS to make the JSON component wider
                            gr.HTML("""
                            <style>
                            #extracted_data_log {
                                width: 100% !important;
                                max-width: 100% !important;
                            }
                            .json-component {
                                width: 100% !important;
                                max-width: 100% !important;
                            }
                            </style>
                            """)
                            
                            # Add export status message
                            export_status = gr.Textbox(
                                label="Export Status",
                                visible=True,
                                interactive=False
                            )
                            
                            with gr.Row():
                                export_data_button = gr.Button("📤 Export Data", variant="primary")
                                clear_data_button = gr.Button("🧹 Clear Data", variant="secondary")
                        
                    with gr.Row():
                            run_button = gr.Button("▶️ Run", variant="primary", scale=2)
                            stop_button = gr.Button("⏹️ Stop", variant="stop", scale=1)
                    
                    with gr.Column(scale=3):
                        stream_output = gr.HTML(
                            label="Browser View",
                            value="<h1 style='width:80vw; height:60vh'>Browser view will appear here when running</h1>",
                        )
            
            with gr.TabItem("🎮 Task Playlists", id=5):
                # Playlist management
                with gr.Row():
                    with gr.Column(scale=3):
                        playlist_name_input = gr.Textbox(
                            label="Playlist Name",
                            placeholder="Enter a name for your playlist",
                            interactive=True
                        )
                    with gr.Column(scale=1):
                        save_playlist_button = gr.Button("💾 Save Playlist")
                
                with gr.Row():
                    with gr.Column(scale=3):
                        playlist_description_input = gr.Textbox(
                            label="Description",
                            placeholder="Enter a description for your playlist",
                            interactive=True
                        )
                
                # Initialize playlists
                playlists = load_saved_playlists_for_ui()
                logger.info(f"Initialized playlist dropdown with {len(playlists)} playlists")
                
                with gr.Row():
                    with gr.Column(scale=3):
                        playlist_dropdown = gr.Dropdown(
                            label="Saved Playlists",
                            choices=playlists,
                            value=None,  # Start with no selection
                            info="Select a playlist to load",
                            interactive=True,
                            allow_custom_value=False,
                        )
                    with gr.Column(scale=1):
                        with gr.Row():
                            refresh_playlists_button = gr.Button("🔄 Refresh")
                            load_playlist_button = gr.Button("📂 Load")
                    with gr.Column(scale=1):
                        delete_playlist_button = gr.Button("🗑️ Delete")
                
                # Playlist status message
                playlist_feedback = gr.Textbox(
                    label="Status",
                    interactive=False,
                    visible=True
                )
                
                with gr.Row():
                    with gr.Column(scale=3):
                        # Use regular Dataframe instead of CustomDataFrameComponent
                        playlist_tasks = gr.Dataframe(
                            headers=["Task Name", "Description"],
                            datatype=["str", "str"],
                            row_count=10,
                            col_count=(2, "fixed"),
                            interactive=False,
                            wrap=True
                        )
                    with gr.Column(scale=1):
                        with gr.Row():
                            move_up_button = gr.Button("⬆️ Move Up")
                        with gr.Row():
                            move_down_button = gr.Button("⬇️ Move Down")
                        with gr.Row():
                            remove_task_button = gr.Button("❌ Remove")
                
                # Available tasks to add to playlist
                with gr.Row():
                    with gr.Column(scale=3):
                        available_tasks_dropdown = gr.Dropdown(
                            label="Available Tasks",
                            choices=[],
                            value=None,  # Start with no selection
                            info="Select a task to add to the playlist",
                            interactive=True,
                            allow_custom_value=False,
                        )
                    with gr.Column(scale=1):
                        refresh_tasks_button = gr.Button("🔄 Refresh Tasks")
                        add_to_playlist_button = gr.Button("➕ Add to Playlist")
                
                # Playlist controls
                with gr.Row():
                    play_playlist_button = gr.Button("▶️ Play Playlist", variant="primary", scale=2)
                    stop_playlist_button = gr.Button("⏹️ Stop", variant="stop", scale=1)
                
                # Current task display
                current_task_display = gr.Textbox(
                    label="Current Task",
                    interactive=False,
                    visible=True
                )
                
                # Connect event handlers
                refresh_playlists_button.click(
                    fn=load_saved_playlists_for_ui,
                    inputs=[],
                    outputs=[playlist_dropdown]
                )
                
                load_playlist_button.click(
                    fn=load_selected_playlist_for_ui,
                    inputs=[playlist_dropdown],
                    outputs=[playlist_tasks, playlist_name_input, playlist_description_input, playlist_feedback]
                )
                
                save_playlist_button.click(
                    fn=save_current_playlist_for_ui,
                    inputs=[playlist_name_input, playlist_description_input, playlist_tasks],
                    outputs=[playlist_dropdown, playlist_feedback, playlist_tasks]
                )
                
                delete_playlist_button.click(
                    fn=delete_selected_playlist_for_ui,
                    inputs=[playlist_dropdown],
                    outputs=[playlist_dropdown, playlist_feedback]
                )
                
                # Initialize available tasks dropdown
                refresh_tasks_button.click(
                    fn=update_available_tasks_for_ui,
                    inputs=[],
                    outputs=[available_tasks_dropdown]
                )
                
                # Add task to playlist
                add_to_playlist_button.click(
                    fn=add_task_to_playlist_for_ui,
                    inputs=[available_tasks_dropdown, playlist_tasks],
                    outputs=[playlist_tasks, playlist_feedback]
                )
                
                # Remove task from playlist
                remove_task_button.click(
                    fn=remove_task_from_playlist_for_ui,
                    inputs=[gr.State(0), playlist_tasks],  # Default to first task
                    outputs=[playlist_tasks, playlist_feedback]
                )
                
                # Move task up
                move_up_button.click(
                    fn=move_task_up_for_ui,
                    inputs=[gr.State(0), playlist_tasks],  # Default to first task
                    outputs=[playlist_tasks, playlist_feedback]
                )
                
                # Move task down
                move_down_button.click(
                    fn=move_task_down_for_ui,
                    inputs=[gr.State(0), playlist_tasks],  # Default to first task
                    outputs=[playlist_tasks, playlist_feedback]
                )
                
                # Play playlist
                play_playlist_button.click(
                    fn=play_playlist_for_ui,
                    inputs=[
                        playlist_tasks,
                        agent_type, llm_provider, llm_model_name, llm_num_ctx, llm_temperature, llm_base_url, llm_api_key,
                        use_own_browser, keep_browser_open, headless, disable_security, window_w, window_h,
                        save_recording_path, save_agent_history_path, save_trace_path,
                        enable_recording, max_steps, use_vision, max_actions_per_step, tool_calling_method
                    ],
                    outputs=[
                        current_task_display,
                        play_playlist_button,
                        stop_playlist_button,
                        playlist_feedback
                    ]
                )
                
                # Stop playlist
                stop_playlist_button.click(
                    fn=stop_agent,
                    inputs=[],
                    outputs=[playlist_feedback, stop_playlist_button, play_playlist_button]
                )
            
            with gr.TabItem("🧐 Deep Research", id=6):
                research_task_input = gr.Textbox(label="Research Task", lines=5, value="Compose a report on the use of Reinforcement Learning for training Large Language Models, encompassing its origins, current advancements, and future prospects, substantiated with examples of relevant models and techniques. The report should reflect original insights and analysis, moving beyond mere summarization of existing literature.")
                with gr.Row():
                    max_search_iteration_input = gr.Number(label="Max Search Iteration", value=3, precision=0) # precision=0 确保是整数
                    max_query_per_iter_input = gr.Number(label="Max Query per Iteration", value=1, precision=0) # precision=0 确保是整数
                with gr.Row():
                    research_button = gr.Button("▶️ Run Deep Research", variant="primary", scale=2)
                    stop_research_button = gr.Button("⏹️ Stop", variant="stop", scale=1)
                markdown_output_display = gr.Markdown(label="Research Report")
                markdown_download = gr.File(label="Download Research Report")


            with gr.TabItem("📊 Results", id=7):
                with gr.Group():
                    # Add tabs for different types of logs
                    with gr.Tabs():
                        with gr.TabItem("📋 Extracted Data Log"):
                            # Add data filtering controls
                            with gr.Row():
                                with gr.Column(scale=1):
                                    # Common data types that should always be available
                                    default_data_types = ["all", "terminal_log", "agent_action", "agent_thought", 
                                                         "extracted_data", "webpage", "html", "error", "system", "other", "unknown"]
                                    data_type_dropdown = gr.Dropdown(
                                        choices=default_data_types,
                                        value="all",
                                        label="Data Type",
                                        interactive=True
                                    )
                                with gr.Column(scale=1):
                                    # Common data sources that should always be available
                                    default_data_sources = ["all", "terminal_log", "agent_action", "agent_thought", 
                                                          "extracted_data", "error", "system", "other", "unknown"]
                                    data_source_dropdown = gr.Dropdown(
                                        choices=default_data_sources,
                                        value="all",
                                        label="Data Source",
                                        interactive=True
                                    )
                                with gr.Column(scale=2):
                                    data_search_input = gr.Textbox(
                                        label="Search Data",
                                        placeholder="Enter search term...",
                                        interactive=True
                                    )
                            
                            # Add data statistics display
                            with gr.Row():
                                data_stats_json = gr.JSON(label="Data Statistics", value={})
                            
                            # Extracted data display
                            extracted_data_log = gr.JSON(
                                label="Extracted Data",
                                value=extracted_data_collector.get_data(),
                                height=500,
                                elem_id="extracted_data_log"
                            )
                            
                            # Add custom CSS to make the JSON component wider
                            gr.HTML("""
                            <style>
                            #extracted_data_log {
                                width: 100% !important;
                            }
                            .json-component {
                                width: 100% !important;
                                max-width: 100% !important;
                            }
                            .json-component pre {
                                font-size: 14px !important;
                                line-height: 1.5 !important;
                                white-space: pre-wrap !important;
                                word-break: break-word !important;
                            }
                            </style>
                            """)
                            
                            # Buttons for data management
                            with gr.Row():
                                update_extracted_data_button = gr.Button("🔄 Refresh Data", variant="primary")
                                export_data_button = gr.Button("💾 Export Data")
                                clear_data_button = gr.Button("🗑️ Clear Data")
                        
                        with gr.TabItem("🔄 Process Log"):
                            # Add log filtering controls
                            with gr.Row():
                                with gr.Column(scale=1):
                                    log_category_dropdown = gr.Dropdown(
                                        choices=["all", "agent_action", "agent_thought", "extracted_data", "error", "system", "other", "terminal_log", "unknown"],
                                        value="all",
                                        label="Log Category",
                                        interactive=True
                                    )
                                with gr.Column(scale=1):
                                    log_level_dropdown = gr.Dropdown(
                                        choices=["ALL", "INFO", "WARNING", "ERROR", "DEBUG"],
                                        value="ALL",
                                        label="Log Level",
                                        interactive=True
                                    )
                                with gr.Column(scale=2):
                                    log_search_input = gr.Textbox(
                                        label="Search Logs",
                                        placeholder="Enter search term...",
                                        interactive=True
                                    )
                            
                            # Add log statistics display
                            with gr.Row():
                                log_stats_json = gr.JSON(label="Log Statistics", value={})
                            
                            # Process log display
                            process_log_data = gr.Textbox(
                                label="Process Log",
                                value="",
                                lines=25,
                                max_lines=50,
                                interactive=False,
                                elem_id="process_log_data"
                            )
                            
                            # Add custom CSS to make the process log look like a terminal
                            gr.HTML("""
                            <style>
                            #process_log_data textarea {
                                font-family: 'Courier New', monospace !important;
                                background-color: #1e1e1e !important;
                                color: #f0f0f0 !important;
                                padding: 10px !important;
                                border-radius: 5px !important;
                                border: 1px solid #444 !important;
                                min-height: 600px !important;
                                height: 600px !important;
                                overflow-y: auto !important;
                                white-space: pre !important;
                                line-height: 1.4 !important;
                                font-size: 14px !important;
                            }
                            </style>
                            """)
                            
                            # Buttons for log management
                            with gr.Row():
                                update_process_log_button = gr.Button("🔄 Refresh Log", variant="primary")
                                export_process_log_button = gr.Button("💾 Export Log")
                                clear_process_log_button = gr.Button("🗑️ Clear Log")

                    recording_display = gr.Video(label="Latest Recording")

                    gr.Markdown("### Results")
                    with gr.Row():
                        with gr.Column():
                            final_result_output = gr.Textbox(
                                label="Final Result", lines=3, show_label=True
                            )
                        with gr.Column():
                            errors_output = gr.Textbox(
                                label="Errors", lines=3, show_label=True
                            )
                    with gr.Row():
                        with gr.Column():
                            model_actions_output = gr.Textbox(
                                label="Model Actions", lines=3, show_label=True
                            )
                        with gr.Column():
                            model_thoughts_output = gr.Textbox(
                                label="Model Thoughts", lines=3, show_label=True
                            )

                    trace_file = gr.File(label="Trace File")

                    agent_history_file = gr.File(label="Agent History")
                    
                    # Add export button for agent history
                    with gr.Row():
                        export_history_button = gr.Button("📤 Export Agent History", variant="secondary")

            with gr.TabItem("📁 Configuration", id=9):
                with gr.Group():
                    config_file_input = gr.File(
                        label="Load Config File",
                        file_types=[".pkl"],
                        interactive=True
                    )

                    load_config_button = gr.Button("Load Existing Config From File", variant="primary")
                    save_config_button = gr.Button("Save Current Config", variant="primary")

                    config_status = gr.Textbox(
                        label="Status",
                        lines=2,
                        interactive=False
                    )

                load_config_button.click(
                    fn=update_ui_from_config,
                    inputs=[config_file_input],
                    outputs=[
                        agent_type, max_steps, max_actions_per_step, use_vision, tool_calling_method,
                        llm_provider, llm_model_name, llm_num_ctx, llm_temperature, llm_base_url, llm_api_key,
                        use_own_browser, keep_browser_open, headless, disable_security, enable_recording,
                        window_w, window_h, save_recording_path, save_trace_path, save_agent_history_path,
                        task, config_status
                    ]
                )

                save_config_button.click(
                    fn=save_current_config,
                    inputs=[
                        agent_type, max_steps, max_actions_per_step, use_vision, tool_calling_method,
                        llm_provider, llm_model_name, llm_num_ctx, llm_temperature, llm_base_url, llm_api_key,
                        use_own_browser, keep_browser_open, headless, disable_security,
                        enable_recording, window_w, window_h, save_recording_path, save_trace_path,
                        save_agent_history_path, task,
                    ],  
                    outputs=[config_status]
                )


        # Attach the callback to the LLM provider dropdown
        llm_provider.change(
            lambda provider, api_key, base_url: update_model_dropdown(provider, api_key, base_url),
            inputs=[llm_provider, llm_api_key, llm_base_url],
            outputs=llm_model_name
        )

        # Add this after defining the components
        enable_recording.change(
            lambda enabled: gr.update(interactive=enabled),
            inputs=enable_recording,
            outputs=save_recording_path
        )

        use_own_browser.change(fn=close_global_browser)
        keep_browser_open.change(fn=close_global_browser)

        # Function to update task templates dropdown
        def update_task_templates_dropdown():
            tasks = load_tasks()
            return gr.Dropdown(choices=[task["name"] for task in tasks])
        
        # Function to load selected task template
        def load_task_template(template_name):
            if not template_name:
                return "", ""
            
            tasks = load_tasks()
            for task in tasks:
                if task["name"] == template_name:
                    return task.get("description", ""), task.get("additional_info", "")
            
            return "", ""
        
        # Function to save current task
        def save_current_task(task_description, additional_info):
            if not task_description.strip():
                return gr.Textbox(value="Task description cannot be empty", visible=True), gr.Dropdown(choices=[])
            
            task_name = task_description.split("\n")[0][:50]  # Use first line as name, limit to 50 chars
            save_task(task_name, task_description, additional_info)
            
            # Update dropdown
            tasks = load_tasks()
            return gr.Textbox(value=f"Task '{task_name}' saved successfully"), gr.Dropdown(choices=[task["name"] for task in tasks])
        
        # Connect event handlers for task templates
        refresh_templates_button.click(
            fn=update_task_templates_dropdown,
                    inputs=[],
            outputs=[task_template_dropdown]
        )
        
        task_template_dropdown.change(
            fn=load_task_template,
            inputs=[task_template_dropdown],
            outputs=[task, add_infos]
        )
        
        save_task_button.click(
            fn=save_current_task,
            inputs=[task, add_infos],
            outputs=[task_feedback, task_template_dropdown]
        )
        
        # Initialize task templates dropdown on page load
        demo.load(
            fn=update_task_templates_dropdown,
            inputs=[],
            outputs=[task_template_dropdown]
        )

        # Function to update the process log data with filtering
        def update_process_log_data(category="all", level="ALL", search_term=""):
            """
            Update the process log display with filtered data.
            
            Args:
                category: Category to filter logs by
                level: Log level to filter by
                search_term: Text to search for within logs
                
            Returns:
                Tuple of (filtered_logs, log_stats)
            """
            try:
                # Helper function for sanitizing inputs locally
                def safe_sanitize(value, default=None):
                    """Local sanitize function to avoid reference errors"""
                    # Handle None or empty values
                    if value is None:
                        return default
                        
                    # Handle list values from Gradio dropdowns
                    if isinstance(value, list):
                        if len(value) > 0:
                            # Get the first item for single-select dropdowns
                            value = value[0]
                        else:
                            return default
                    
                    # Handle empty strings
                    if isinstance(value, str) and not value.strip():
                        return default
                        
                    # Return the value with proper type conversion for common types
                    if isinstance(value, (int, float)):
                        return value
                    elif isinstance(value, str):
                        return value
                    else:
                        # Safe conversion to string for other types
                        try:
                            return str(value)
                        except:
                            return default
                
                # Sanitize inputs
                category_str = safe_sanitize(category, default="all")
                level_str = safe_sanitize(level, default="ALL")
                search_term_str = safe_sanitize(search_term, default="")
                
                # Get filtered logs
                filtered_logs = ""
                if search_term_str:
                    # Search term takes precedence
                    filtered_logs = data_log_handler.search_logs(search_term_str)
                elif level_str != "ALL":
                    # Then filter by level
                    filtered_logs = data_log_handler.get_logs_by_level(level_str)
                else:
                    # Otherwise filter by category
                    filtered_logs = data_log_handler.get_logs_by_category(category_str)
                
                # Get updated stats
                log_stats = data_log_handler.get_stats()
                
                return filtered_logs, log_stats
                
            except Exception as e:
                logging.error(f"Error updating process log data: {str(e)}")
                return f"Error updating logs: {str(e)}", json.dumps({"error": str(e)})
        
        # Create a tab for viewing agent activity and logs
        with gr.Tab("Agent Activity"):
            with gr.Row():
                with gr.Column(scale=1):
                    # Log filtering controls
                    log_category_dropdown = gr.Dropdown(
                        choices=['all', 'agent_action', 'agent_thought', 'agent_memory', 'agent_planning', 
                                'agent_evaluation', 'agent_task_progress', 'extracted_data', 'error', 'system', 'other'],
                        value='all',
                        label="Log Category",
                        info="Filter logs by category"
                    )
                    
                    log_level_dropdown = gr.Dropdown(
                        choices=['ALL', 'DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'],
                        value='ALL',
                        label="Log Level",
                        info="Filter logs by level"
                    )
                    
                    log_search_input = gr.Textbox(
                        label="Search Logs",
                        placeholder="Enter search term",
                        info="Search logs for specific text"
                    )
                    
                    update_logs_button = gr.Button("Refresh Logs", variant="primary")
                    clear_logs_button = gr.Button("Clear Logs", variant="secondary")
                    
                    log_stats_json = gr.JSON(
                        label="Log Statistics",
                        value={},
                        visible=True
                    )
                    
                with gr.Column(scale=3):
                    agent_log_display = gr.Textbox(
                        label="Agent Activity Log",
                        placeholder="Agent logs will appear here",
                        lines=30,
                        max_lines=50,
                        interactive=False
                    )
                    
                    export_logs_button = gr.Button("Export Logs")
            
            # Function to update agent logs
            def update_agent_logs(category, level, search_term):
                """
                Update the agent log display with filtered data.
                
                Args:
                    category: Category to filter logs by
                    level: Log level to filter by
                    search_term: Text to search for within logs
                    
                Returns:
                    Tuple of (filtered_logs, log_stats)
                """
                try:
                    # Helper function for sanitizing inputs locally
                    def safe_sanitize(value, default=None):
                        """Local sanitize function to avoid reference errors"""
                        # Handle None or empty values
                        if value is None:
                            return default
                            
                        # Handle list values from Gradio dropdowns
                        if isinstance(value, list):
                            if len(value) > 0:
                                # Get the first item for single-select dropdowns
                                value = value[0]
                            else:
                                return default
                        
                        # Handle empty strings
                        if isinstance(value, str) and not value.strip():
                            return default
                            
                        # Return the value with proper type conversion for common types
                        if isinstance(value, (int, float)):
                            return value
                        elif isinstance(value, str):
                            return value
                        else:
                            # Safe conversion to string for other types
                            try:
                                return str(value)
                            except:
                                return default
                    
                    # Sanitize inputs 
                    category_str = safe_sanitize(category, default="all")
                    level_str = safe_sanitize(level, default="ALL")
                    search_term_str = safe_sanitize(search_term, default="")
                    
                    # Get filtered logs
                    filtered_logs = ""
                    if search_term_str:
                        # Search term takes precedence
                        filtered_logs = data_log_handler.search_logs(search_term_str)
                    elif level_str != "ALL":
                        # Then filter by level
                        filtered_logs = data_log_handler.get_logs_by_level(level_str)
                    else:
                        # Otherwise filter by category
                        filtered_logs = data_log_handler.get_logs_by_category(category_str)
                    
                    # Get updated stats
                    log_stats = data_log_handler.get_stats()
                    
                    return filtered_logs, log_stats
                except Exception as e:
                    logging.error(f"Error updating agent logs: {str(e)}")
                    return f"Error updating logs: {str(e)}", json.dumps({"error": str(e)})
            
            # Function to clear agent logs
            def clear_agent_logs():
                """Clear all agent logs."""
                data_log_handler.clear_logs()
                return "", json.dumps({})
            
            # Function to export agent logs
            def export_agent_logs(category, level, search_term):
                """
                Export agent logs to a file.
                
                Args:
                    category: Category to filter logs by
                    level: Log level to filter by
                    search_term: Text to search for within logs
                    
                Returns:
                    String with export status message
                """
                try:
                    # Get filtered logs
                    logs, _ = update_agent_logs(category, level, search_term)
                    
                    # Create a user downloads directory if it doesn't exist
                    user_downloads = os.path.expanduser("~/Downloads/browser-use-exports")
                    os.makedirs(user_downloads, exist_ok=True)
                    
                    # Generate filename with timestamp
                    timestamp = time.strftime("%Y%m%d_%H%M%S")
                    filename = f"agent_logs_{timestamp}.txt"
                    filepath = os.path.join(user_downloads, filename)
                    
                    # Write logs to file
                    with open(filepath, 'w') as f:
                        f.write(logs)
                    
                    return f"Logs exported to: {filepath}"
                except Exception as e:
                    logging.error(f"Error exporting agent logs: {str(e)}")
                    return f"Error exporting logs: {str(e)}"
            
            # Connect the update button
            update_logs_button.click(
                fn=update_agent_logs,
                inputs=[log_category_dropdown, log_level_dropdown, log_search_input],
                outputs=[agent_log_display, log_stats_json]
            )
            
            # Connect clear button
            clear_logs_button.click(
                fn=clear_agent_logs,
                inputs=[],
                outputs=[agent_log_display, log_stats_json]
            )
            
            # Connect export button
            export_logs_button.click(
                fn=export_agent_logs,
                inputs=[log_category_dropdown, log_level_dropdown, log_search_input],
                outputs=[gr.Textbox(label="Export Status")]
            )
            
            # Auto-refresh logs every 5 seconds
            gr.HTML("""
            <script>
            function refreshAgentLogs() {
                // Find the update logs button
                var buttons = document.querySelectorAll('button');
                var updateButton = null;
                for (var i = 0; i < buttons.length; i++) {
                    if (buttons[i].textContent.includes('Refresh Logs')) {
                        updateButton = buttons[i];
                        break;
                    }
                }
                
                if (updateButton) {
                    updateButton.click();
                }
                
                // Schedule the next refresh
                setTimeout(refreshAgentLogs, 5000);
            }
            
            // Start refreshing after page load
            document.addEventListener('DOMContentLoaded', function() {
                setTimeout(refreshAgentLogs, 5000);
            });
            </script>
            """)

        # Function to export process log
        def export_process_log(category, level, search_term):
            """
            Export process logs to a file.
            
            Args:
                category: Category to filter logs by
                level: Log level to filter by
                search_term: Text to search for within logs
                
            Returns:
                String with export status message
            """
            try:
                # Helper function for sanitizing inputs locally
                def safe_sanitize(value, default=None):
                    """Local sanitize function to avoid reference errors"""
                    # Handle None or empty values
                    if value is None:
                        return default
                        
                    # Handle list values from Gradio dropdowns
                    if isinstance(value, list):
                        if len(value) > 0:
                            # Get the first item for single-select dropdowns
                            value = value[0]
                        else:
                            return default
                    
                    # Handle empty strings
                    if isinstance(value, str) and not value.strip():
                        return default
                        
                    # Return the value with proper type conversion for common types
                    if isinstance(value, (int, float)):
                        return value
                    elif isinstance(value, str):
                        return value
                    else:
                        # Safe conversion to string for other types
                        try:
                            return str(value)
                        except:
                            return default
                            
                # Sanitize inputs
                category_str = safe_sanitize(category, default="all")
                level_str = safe_sanitize(level, default="ALL")
                search_term_str = safe_sanitize(search_term, default="")
                
                # Get filtered logs directly without using update_process_log_data
                filtered_logs = ""
                if search_term_str:
                    # Search term takes precedence
                    filtered_logs = data_log_handler.search_logs(search_term_str)
                elif level_str != "ALL":
                    # Then filter by level
                    filtered_logs = data_log_handler.get_logs_by_level(level_str)
                else:
                    # Otherwise filter by category
                    filtered_logs = data_log_handler.get_logs_by_category(category_str)
                
                try:
                    # Create a timestamp for the filename
                    timestamp = time.strftime("%Y%m%d_%H%M%S")
                    filename = f"process_log_{timestamp}.txt"
                    
                    # Create a user downloads directory if it doesn't exist
                    user_downloads = os.path.expanduser("~/Downloads/browser-use-exports")
                    os.makedirs(user_downloads, exist_ok=True)
                    
                    # Create the log file
                    log_file_path = os.path.join(user_downloads, filename)
                    with open(log_file_path, 'w') as f:
                        f.write(filtered_logs)
                    
                    return f"Process log exported to: {log_file_path}"
                except Exception as e:
                    return f"Error exporting process log: {str(e)}"
            except Exception as e:
                logging.error(f"Error in export_process_log: {str(e)}")
                return f"Error exporting process log: {str(e)}"

        # Function to clear process log
        def clear_process_log():
            """
            Clear all process logs.
            
            Returns:
                Empty string for logs and empty dict for stats
            """
            data_log_handler.clear_logs()
            return "", json.dumps({})
        
        # Connect the update button to the process log with filtering
        update_process_log_button.click(
            fn=update_process_log_data,
            inputs=[log_category_dropdown, log_level_dropdown, log_search_input],
            outputs=[process_log_data, log_stats_json]
        )
        
        # Connect the dropdowns and search to auto-update
        log_category_dropdown.change(
            fn=update_process_log_data,
            inputs=[log_category_dropdown, log_level_dropdown, log_search_input],
            outputs=[process_log_data, log_stats_json]
        )
        
        log_level_dropdown.change(
            fn=update_process_log_data,
            inputs=[log_category_dropdown, log_level_dropdown, log_search_input],
            outputs=[process_log_data, log_stats_json]
        )
        
        log_search_input.submit(
            fn=update_process_log_data,
            inputs=[log_category_dropdown, log_level_dropdown, log_search_input],
            outputs=[process_log_data, log_stats_json]
        )

        # Function to update the extracted data with filtering
        def update_extracted_data(data_type="all", data_source="all", search_term=""):
            """
            Function to update the extracted data with filtering
            
            Args:
                data_type: Type of data to filter (str or list)
                data_source: Source of data to filter (str or list)
                search_term: Text to search for in the data (str)
                
            Returns:
                Tuple of (filtered_data, metadata)
            """
            try:
                # Helper function for sanitizing inputs locally
                def safe_sanitize(value, default=None):
                    """Local sanitize function to avoid reference errors"""
                    # Handle None or empty values
                    if value is None:
                        return default
                        
                    # Handle list values from Gradio dropdowns
                    if isinstance(value, list):
                        if len(value) > 0:
                            # Get the first item for single-select dropdowns
                            value = value[0]
                        else:
                            return default
                    
                    # Handle empty strings
                    if isinstance(value, str) and not value.strip():
                        return default
                        
                    # Return the value with proper type conversion for common types
                    if isinstance(value, (int, float)):
                        return value
                    elif isinstance(value, str):
                        return value
                    else:
                        # Safe conversion to string for other types
                        try:
                            return str(value)
                        except:
                            return default
                
                # Sanitize inputs
                data_type_str = safe_sanitize(data_type, default="all")
                data_source_str = safe_sanitize(data_source, default="all")
                search_term_str = safe_sanitize(search_term, default="")
                
                # Get metadata for dropdown updates
                metadata = extracted_data_collector.get_metadata()
                
                # Define default types and sources here in the function scope
                default_types = ["all", "terminal_log", "agent_action", "agent_thought", "extracted_data", "webpage", "html", "error", "system", "other", "unknown"]
                default_sources = ["all", "terminal_log", "agent_action", "agent_thought", "extracted_data", "error", "system", "other", "unknown"]
                
                # Filter data using clean inputs
                filtered_data = []
                
                try:
                    if data_type_str != "all" and data_source_str != "all":
                        # Filter by both type and source
                        type_data = extracted_data_collector.get_data_by_type(data_type_str)
                        filtered_data = [
                            item for item in type_data
                            if item.get("source") == data_source_str
                        ]
                    elif data_type_str != "all":
                        filtered_data = extracted_data_collector.get_data_by_type(data_type_str)
                    elif data_source_str != "all":
                        filtered_data = extracted_data_collector.get_data_by_source(data_source_str)
                    else:
                        filtered_data = extracted_data_collector.get_data()
                        
                    # Apply search term if provided
                    if search_term_str:
                        # Ensure search term is a string
                        search_term_lower = str(search_term_str).lower()
                        filtered_data = [
                            item for item in filtered_data
                            if search_term_lower in json.dumps(item).lower()
                        ]
                except Exception as e:
                    logging.error(f"Error filtering data: {str(e)}")
                    filtered_data = []
                    
                # Return just the data and metadata, not the dropdown choices
                return filtered_data, metadata
                
            except Exception as e:
                logging.error(f"Error in update_extracted_data: {str(e)}")
                # Return safe defaults if anything fails
                return [], {"types": [], "sources": []}
        
        # Connect the update button to the extracted data with filtering
        update_extracted_data_button.click(
            fn=update_extracted_data,
            inputs=[data_type_dropdown, data_source_dropdown, data_search_input],
            outputs=[extracted_data_log, data_stats_json, data_type_dropdown, data_source_dropdown]
        )
        
        # Connect the dropdowns and search to auto-update
        data_type_dropdown.change(
            fn=update_extracted_data,
            inputs=[data_type_dropdown, data_source_dropdown, data_search_input],
            outputs=[extracted_data_log, data_stats_json, data_type_dropdown, data_source_dropdown]
        )
        
        data_source_dropdown.change(
            fn=update_extracted_data,
            inputs=[data_type_dropdown, data_source_dropdown, data_search_input],
            outputs=[extracted_data_log, data_stats_json, data_type_dropdown, data_source_dropdown]
        )
        
        data_search_input.submit(
            fn=update_extracted_data,
            inputs=[data_type_dropdown, data_source_dropdown, data_search_input],
            outputs=[extracted_data_log, data_stats_json, data_type_dropdown, data_source_dropdown]
        )
        
        # Function to export extracted data
        def export_extracted_data(data_type, data_source, search_term):
            # Get filtered data
            filtered_data, _ = update_extracted_data(data_type, data_source, search_term)
            
            try:
                # Create a timestamp for the filename
                import datetime
                timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                
                # Create a user downloads directory if it doesn't exist
                user_downloads = os.path.expanduser("~/Downloads/browser-use-exports")
                os.makedirs(user_downloads, exist_ok=True)
                
                # Create a more descriptive filename
                filename_parts = []
                if data_type and data_type != "all":
                    filename_parts.append(data_type)
                if data_source and data_source != "all":
                    filename_parts.append(data_source)
                if search_term:
                    # Limit search term length in filename
                    safe_term = search_term[:20].replace(" ", "_")
                    if safe_term:
                        filename_parts.append(safe_term)
                
                # Default to "full_export" if no specific filters
                base_name = "_".join(filename_parts) if filename_parts else "full_export"
                export_path = os.path.join(user_downloads, f"{base_name}_{timestamp}.json")
                
                # Ensure we're not truncating any webpage content
                for item in filtered_data:
                    # Make sure we're preserving full HTML content
                    if "html_content" in item and isinstance(item["html_content"], str) and len(item["html_content"]) > 1000000:
                        # Log that we're preserving large HTML content
                        logging.info(f"Preserving large HTML content ({len(item['html_content'])} bytes) in export")
                
                # Write the data to the file with pretty formatting for readability
                with open(export_path, 'w', encoding='utf-8') as f:
                    json.dump(filtered_data, f, indent=2, ensure_ascii=False)
                
                # Log the export for tracking
                logging.info(f"Exported {len(filtered_data)} items to {export_path}")
                
                return f"Extracted data exported to: {export_path}"
            except Exception as e:
                logging.error(f"Error exporting data: {str(e)}")
                return f"Error exporting extracted data: {str(e)}"
        
        # Function to clear extracted data
        def clear_extracted_data():
            extracted_data_collector.clear_data()
            return [], extracted_data_collector.get_metadata()
        
        # Bind the export and clear buttons
        export_data_button.click(
            fn=export_extracted_data,
            inputs=[data_type_dropdown, data_source_dropdown, data_search_input],
            outputs=[gr.Textbox(label="Export Status")]
        )
        
        clear_data_button.click(
            fn=clear_extracted_data,
            inputs=[],
            outputs=[extracted_data_log, data_stats_json, data_type_dropdown, data_source_dropdown]
        )
        
        # Update the extracted data when the page loads
        demo.load(
            fn=update_extracted_data,
            inputs=[data_type_dropdown, data_source_dropdown, data_search_input],
            outputs=[extracted_data_log, data_stats_json, data_type_dropdown, data_source_dropdown]
        )
        
        # Add JavaScript to update the extracted data periodically
        js_update_data = """
        <script>
        // Function to update the extracted data
        function updateExtractedData() {
            // Find the update button by its text content
            var buttons = document.querySelectorAll('button');
            var updateButton = null;
            for (var i = 0; i < buttons.length; i++) {
                if (buttons[i].textContent.includes('Refresh Data')) {
                    updateButton = buttons[i];
                    break;
                }
            }
            
            if (updateButton) {
                updateButton.click();
            } else {
                console.log('Update data button not found');
            }
            
        # Add function to export agent history
        # Add function to export agent history
        def export_agent_history(history_file_path):
        
        // Start updating the extracted data when the page loads
        document.addEventListener('DOMContentLoaded', function() {
            // Wait a bit for the UI to initialize
            setTimeout(updateExtractedData, 5000);
        });
        </script>
            

        # Add function to export agent history
        def export_agent_history(history_file_path):
            if not history_file_path or not os.path.exists(history_file_path):
                return "No agent history file available to export."
            
            try:
                # Get the filename from the path
                filename = os.path.basename(history_file_path)
                
                # Create a user downloads directory if it doesn't exist
                user_downloads = os.path.expanduser("~/Downloads/browser-use-exports")
                os.makedirs(user_downloads, exist_ok=True)
                
                # Copy the file to the user's downloads directory
                export_path = os.path.join(user_downloads, filename)
                shutil.copy2(history_file_path, export_path)
                
                return f"Agent history exported to: {export_path}"
            except Exception as e:
                return f"Error exporting agent history: {str(e)}"
        
        # Bind the export button click event
        export_history_button.click(
            fn=export_agent_history,
            inputs=[agent_history_file],
            outputs=[gr.Textbox(label="Export Status")]
        )

        # Run button click handler
        run_button.click(
            fn=run_with_stream,
                inputs=[
                    agent_type, llm_provider, llm_model_name, llm_num_ctx, llm_temperature, llm_base_url, llm_api_key,
                    use_own_browser, keep_browser_open, headless, disable_security, window_w, window_h,
                    save_recording_path, save_agent_history_path, save_trace_path,  # Include the new path
                    enable_recording, task, add_infos, max_steps, use_vision, max_actions_per_step, tool_calling_method
                ],
            outputs=[
        stream_output,           # Browser view
                final_result_output,    # Final result
                errors_output,          # Errors
                model_actions_output,   # Model actions
                model_thoughts_output,  # Model thoughts
                recording_display,      # Latest recording
                trace_file,             # Trace file
                agent_history_file,     # Agent history file
                stop_button,            # Stop button
        run_button,             # Run button
        process_log_data         # Process log (added)
    ],
)
        
        # Also update the process log when the run button is clicked
        run_button.click(
            fn=lambda: data_log_handler.get_process_logs(),
            inputs=[],
            outputs=[process_log_data]
        )

        # Bind the stop button click event after errors_output is defined
        stop_button.click(
            fn=stop_agent,
                    inputs=[],
            outputs=[errors_output, stop_button, run_button],
        )

        # Also update the process log when the stop button is clicked
        stop_button.click(
            fn=lambda: data_log_handler.get_process_logs(),
            inputs=[],
            outputs=[process_log_data]
                )

        with gr.TabItem("🎥 Recordings", id=8):
            def list_recordings(save_recording_path):
                if not os.path.exists(save_recording_path):
                    return []

                # Get all video files
                recordings = glob.glob(os.path.join(save_recording_path, "*.[mM][pP]4")) + glob.glob(os.path.join(save_recording_path, "*.[wW][eE][bB][mM]"))

                # Sort recordings by creation time (oldest first)
                recordings.sort(key=os.path.getctime)

                # Add numbering to the recordings
                numbered_recordings = []
                for idx, recording in enumerate(recordings, start=1):
                    filename = os.path.basename(recording)
                    numbered_recordings.append((recording, f"{idx}. {filename}"))

                return numbered_recordings

            recordings_gallery = gr.Gallery(
                label="Recordings",
                value=list_recordings(config['save_recording_path']),
                columns=3,
                height="auto",
                object_fit="contain"
            )

            refresh_button = gr.Button("🔄 Refresh Recordings", variant="secondary")
            refresh_button.click(
                fn=list_recordings,
                inputs=save_recording_path,
                outputs=recordings_gallery
            )

    return demo

def parse_args():
    """
    Parse command-line arguments for the web UI.
    
    Returns:
        argparse.Namespace: Parsed command-line arguments
    """
    import argparse
    
    parser = argparse.ArgumentParser(description="Browser Use Web UI")
    parser.add_argument("--theme", type=str, default="Ocean", help="Theme for the UI")
    parser.add_argument("--config", type=str, default="config.json", help="Path to config file")
    parser.add_argument("--ip", type=str, default="127.0.0.1", help="IP address to bind to")
    parser.add_argument("--port", type=int, default=7788, help="Port to listen on")
    
    return parser.parse_args()

def find_available_port(start_port=7790, max_attempts=10):
    """
    Find an available port starting from the given port.
    
    Args:
        start_port: The port to start checking from
        max_attempts: Maximum number of ports to check
        
    Returns:
        int: An available port or None if none found
    """
    import socket
    
    for port in range(start_port, start_port + max_attempts):
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(1)
        try:
            result = sock.connect_ex(('127.0.0.1', port))
            sock.close()
            if result != 0:  # Port is available
                return port
        except:
            sock.close()
    
    return None  # No available ports found

def main():
    """Main function to start the web UI server"""
    # Parse command line arguments
    args = parse_args()
    
    # Set up logging format
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # Load config
    config_dict = default_config()
    if os.path.exists(args.config):
        loaded_config = load_config_from_file(args.config)
        if isinstance(loaded_config, dict):
            config_dict = loaded_config
    
    # Ensure add_infos is in the config
    if 'add_infos' not in config_dict:
        config_dict['add_infos'] = ""
    
    # Fix any broken playlist files
    playlist_dir = "saved_playlists"
    os.makedirs(playlist_dir, exist_ok=True)
    
    for playlist_file in glob.glob(os.path.join(playlist_dir, "*.json")):
        try:
            # Try to load the file as JSON
            with open(playlist_file, 'r') as f:
                json.loads(f.read())
        except json.JSONDecodeError:
            # File is broken, attempt to fix it
            logging.warning(f"Found corrupted playlist file: {playlist_file}, attempting to fix...")
            if fix_broken_playlist_file(playlist_file):
                logging.info(f"Successfully fixed playlist file: {playlist_file}")
            else:
                logging.error(f"Failed to fix playlist file: {playlist_file}")

    # Create the UI
    demo = create_ui(config_dict, theme_name=args.theme)
    
    # Find an available port
    port = args.port
    if not is_port_available(port):
        # Try to find any available port in a wider range
        available_port = find_available_port(start_port=7790, max_attempts=20)
        if available_port:
            logging.warning(f"Port {port} is busy, using port {available_port} instead")
            port = available_port
        else:
            # Last resort - try port 0 which lets the OS assign a free port
            logging.warning("No specific available ports found, letting OS choose a port")
            port = 0
    
    # Launch the server with improved error handling
    try:
        demo.launch(server_name=args.ip, server_port=port)
    except OSError as e:
        if "Cannot find empty port" in str(e):
            # Final attempt with completely different range
            fallback_port = find_available_port(start_port=8800, max_attempts=50)
            if fallback_port:
                logging.warning(f"Using fallback port {fallback_port}")
                demo.launch(server_name=args.ip, server_port=fallback_port)
            else:
                logging.error("Could not find any available ports")
                sys.exit(1)
        else:
            logging.error(f"Error launching server: {str(e)}")
            raise e

def is_port_available(port):
    """Check if a port is available."""
    import socket
    
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    sock.settimeout(1)
    try:
        result = sock.connect_ex(('127.0.0.1', port))
        sock.close()
        return result != 0  # Port is available if connection fails
    except:
        sock.close()
        return False

if __name__ == '__main__':
    main()

def sanitize_gradio_input(value, default=None):
    """
    Utility function to sanitize inputs from Gradio components.
    Handles conversion from lists to single values and ensures proper string conversion.
    
    Args:
        value: The input value from a Gradio component
        default: Default value if the input is None or empty
        
    Returns:
        Sanitized value suitable for use in backend functions
    """
    try:
        # Handle None or empty values
        if value is None:
            return default
            
        # Handle list values from Gradio dropdowns
        if isinstance(value, list):
            if len(value) > 0:
                # Get the first item for single-select dropdowns
                value = value[0]
            else:
                return default
        
        # Handle empty strings
        if isinstance(value, str) and not value.strip():
            return default
            
        # Return the value with proper type conversion for common types
        if isinstance(value, (int, float)):
            return value
        elif isinstance(value, str):
            return value
        else:
            # Safe conversion to string for other types
            try:
                return str(value)
            except:
                return default
    except Exception as e:
        logging.error(f"Error sanitizing input: {str(e)}")
        return default

def fix_broken_playlist_file(file_path):
    """
    Attempts to fix a broken playlist file by reading as much as possible
    and creating a valid JSON structure if the file is corrupted.
    
    Args:
        file_path: Path to the playlist file
        
    Returns:
        bool: True if fixed successfully, False otherwise
    """
    try:
        # Try to open and read the file
        with open(file_path, 'r') as f:
            content = f.read()
            
        # Try to parse it as JSON
        try:
            json.loads(content)
            # If we get here, the file is valid JSON
            return False  # No fixing needed
        except json.JSONDecodeError:
            # File is broken, create a minimal valid structure
            playlist_name = os.path.basename(file_path).replace('.json', '')
            fixed_content = {
                "name": playlist_name,
                "description": f"Auto-fixed playlist (previously corrupted)",
                "tasks": []
            }
            
            # Write the fixed content back to the file
            with open(file_path, 'w') as f:
                json.dump(fixed_content, f, indent=2)
                
            logging.info(f"Fixed broken playlist file: {file_path}")
            return True
            
    except Exception as e:
        logging.error(f"Failed to fix playlist file {file_path}: {str(e)}")
        return False

# Define AgentTracker class before it's referenced
class AgentTracker:
    """
    Advanced tracker for agent analytics and metrics
    
    Captures detailed information about agent performance including:
    - Success/failure rates of actions
    - Time spent on different types of operations
    - Error patterns and frequencies
    - Memory evolution throughout agent execution
    - Task completion metrics
    """
    
    def __init__(self):
        """Initialize the agent tracker with empty metrics and tracking state"""
        self.metrics = {
            "actions": {"total": 0, "successful": 0, "failed": 0, "unknown": 0},
            "errors": {},
            "thoughts": 0,
            "memory_updates": 0,
            "evaluations": 0,
            "plans": 0,
            "time_spent": {"total": 0, "thinking": 0, "acting": 0, "waiting": 0}
        }
        self.active = False
        self.start_time = None
        self.end_time = None
        self.step_history = []
        self.action_history = []
        self.thought_history = []
        self.memory_history = []
        self.evaluation_history = []
        self.plan_history = []
        self.error_history = []
        self.terminal_logs = []
        import threading
        self.lock = threading.RLock()
        
    def add_terminal_log(self, log_entry):
        """Add a terminal log entry to the tracker"""
        if isinstance(log_entry, str):
            self.terminal_logs.append(log_entry)
            
    def export_to_json(self, filepath=None):
        """
        Export tracking data to JSON
        
        Args:
            filepath (str, optional): Path to save JSON file
            
        Returns:
            str: JSON string if no filepath provided
        """
        import json
        data = {
            "metrics": self.get_current_metrics(),
            "performance_summary": self.get_performance_summary(),
            "sequence_analysis": self.get_sequence_analysis(),
            "step_history": self.step_history,
            "action_history": self.action_history,
            "thought_history": self.thought_history,
            "error_history": self.error_history,
            "terminal_logs": self.terminal_logs,
            "start_time": self.start_time,
            "end_time": self.end_time
        }
        
        json_data = json.dumps(data, indent=2)
        
        if filepath:
            with open(filepath, 'w') as f:
                f.write(json_data)
            return filepath
            
        return json_data
        
    def get_current_metrics(self):
        return self.metrics
        
    def get_performance_summary(self):
        return {}
        
    def get_sequence_analysis(self):
        return {}
        
    def track_action(self, action_data):
        pass
        
    def track_thought(self, thought_data):
        pass
        
    def track_memory(self, memory_data):
        pass
        
    def track_evaluation(self, eval_data):
        pass
        
    def track_plan(self, plan_data):
        pass
        
    def track_error(self, error_data):
        pass

# Global tracker instance
_agent_tracker_instance = None

def get_agent_tracker():
    # Return the global agent tracker instance
    global _agent_tracker_instance
    if _agent_tracker_instance is None:
        # Use the AgentTracker class defined in this file
        _agent_tracker_instance = AgentTracker()
    return _agent_tracker_instance

